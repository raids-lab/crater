---
title: ストレージアーキテクチャ
description: Crater は、ハイパフォーマンスなローカルワークロードと、Pod およびノード間での持続的な共有データアクセスを処理するため、ハイブリッドストレージアーキテクチャを使用しています。このドキュメントでは、クラスターで使用されているストレージソリューションについて説明します。
---

## 1. ローカル永続ボリューム (OpenEBS 経由の LocalPV)

[OpenEBS LocalPV](https://openebs.io/docs/user-guides/localpv)を使用して、高スループットとデータローカリティを必要とするワークロード用のノードローカルストレージを管理します。

### なぜ LocalPV なのか？

- **CRD ベースの管理**: Kubernetes ネイティブな宣言的管理でローカルディスクを管理可能。
- **性能**: データは同じノード上に残り、ネットワークオーバーヘッドを最小限に抑える。
- **Crater での用途**:
  - ジョブキャッシュディレクトリ
  - ローカルデータセットステージング領域
  - ノードごとの推論またはトレーニング用の一時領域

### StorageClass

ローカルディスクのプロビジョニングに専用の`StorageClass`が設定されています。このクラスは以下のような他のチャートから参照されます：
- データベースストレージ用の`cloudnative-pg`
- レプリケーションを必要としない分散ジョブ出力

参照：[`deployments/openebs`](../deployments/openebs)

---

## 2. 共有ブロックストレージ (Rook 経由の Ceph RBD)

複数ノードでアクセス可能な永続ボリュームが必要な場合、Crater は[Rook-Ceph RBD](https://rook.io/docs/rook/latest/ceph-block.html)を使用します。RBD ボリュームは動的にプロビジョニングされ、以下の機能をサポートしています：

- マイグレーションをサポートする ReadWriteOnce アクセス
- レプリケーションと障害復旧
- 以下に適しています：
  - Prometheus TSDB ストレージ
  - 永続性を必要とする Crater の内部サービス
  - ノード間で共有されるデータセット

Ceph が選ばれた理由は以下の通りです：

- Rook 経由で Kubernetes ネイティブなプロビジョニングが可能
- 強力なコミュニティサポート
- スケーラビリティと障害耐性

> 📌 Prometheus などの多くのステートフルコンポーネントは、カスタムの`StorageClass`を介して Ceph RBD ボリュームを使用しています。

---

## ストレージ使用マトリクス

| コンポーネント         | タイプ               | ストレージバックエンド       | メモ                                 |
|------------------------|----------------------|------------------------------|--------------------------------------|
| PostgreSQL (Crater DB) | 永続的               | LocalPV (OpenEBS)            | 高速、ノード特有                     |
| Prometheus TSDB        | 永続的               | Ceph RBD (Rook)              | マルチノード、高耐久性               |
| ユーザージョブ         | 一時的 / 永続的      | LocalPV / Ceph RBD           | 設定に基づく                         |
| Grafana ダッシュボード   | 一時的 / 永続的      | Ceph RBD                     | オプション、ダッシュボード設定に依存 |

---

## メモ

- LocalPV を提供するノードには、常にラベル付けおよびマウントされたディスクパスを確保してください。
- Ceph RBD には、クラスターノード上の事前にプロビジョニングされたブロックストレージデバイスが必要です。
- LocalPV を使用する際は、ノードアフィニティとターレレーションを使用して Pod を正しいストレージ場所にバインドしてください。
- 各チャートのドキュメントを参照して、適切な`StorageClass`の上書き方法をご確認ください。

---

## 関連モジュール

- [`openebs`](./openebs.md)
- [`cloudnative-pg`](./cloudnative-pg.md)
- [`prometheus`](./prometheus.md)

## インストール

NFS をストレージプロビジョーナーとして使用し、Crater で事前に設定された値を使用した公式 Helm チャートを使用することを推奨します。
 
📖 詳細ガイド：[`deployments/nfs/README.md`](../deployments/nfs/README.md)