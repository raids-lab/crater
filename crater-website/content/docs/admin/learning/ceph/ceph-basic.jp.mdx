---
title: "Rook-Ceph プラクティスガイド"
description: "Rook-Ceph 入門ガイド、初心者向けに作成しました！"
---

> このガイドは、Ceph と分散ストレージの経験がまったくない方を対象としており、Rook-Ceph を迅速に理解し、実際に操作できるようにすることを目的としています。

## 一、前提知識

Rook-Ceph の実践に進む前に、2 つの重要な概念、**Ceph** と **Rook-Ceph** の根本的な理解が必要です。これらはそれぞれ、分散ストレージシステムの核心的な能力と、Kubernetes 上での自動運用ソリューションを表しています。

### 1. Ceph

**Ceph はオープンソースの分散ストレージシステム**であり、Sage Weil が開始し、大規模なストレージ環境におけるデータの一貫性、可用性、拡張性の問題を解決することを目的としています。従来の集中型ストレージソリューションとは異なり、Ceph は単一のコントローラーに依存せず、ペアノード間の協調に基づいて構築されています。Ceph の設計目標には以下があります。

* **高拡張性**：数 TB から数 PB までのストレージ容量の増加をサポート；
* **高可用性と耐障害性**：レプリカまたはエラー訂正コードのメカニズムにより、ノードがダウンしてもデータが利用可能に保証；
* **統一ストレージモデル**：ブロックデバイス（Block）、オブジェクトストレージ（Object）、ファイルシステム（File）のすべてのアクセス方式をサポート。

Ceph クラスターには主に以下の核心コンポーネントが含まれます

| コンポーネント                         | 説明                                 |
| ---------------------------- | ---------------------------------------- |
| MON（Monitor）               | クラスターステータス、健康状態チェック、選出などメタデータサービスを提供 |
| OSD（Object Storage Daemon） | データの実際の読み書き、複製、復元などのコア機能を担当 |
| MGR（Manager）               | モニタリング、統計、拡張機能を提供             |
| MDS（Metadata Server、オプション） | ファイルシステムをサポートするためにディレクトリツリーのメタデータを管理 |

Ceph クラスターは通常、3 つ以上の MON が必要で、選出の安全性を確保し、複数の OSD が各ノードの物理ディスクにマウントされ、データストレージ能力を共同で提供します。

### 2. Rook-Ceph

**Rook は Kubernetes 上で動作するストレージオーケストレータ（Operator）** であり、**ストレージシステムを Pod のように管理できるようにすることを目的としています**。Rook-Ceph はその中でも最も成熟し、広く利用されている後端の一つであり、Kubernetes 上での Ceph のデプロイと管理プロセスを簡略化します。

Rook-Ceph は、Ceph のデプロイとメンテナンスを Kubernetes のカスタムリソース（Custom Resources）の一组として抽象化します。これらには以下があります。

| カスタムリソース        | 説明                         |
| ----------------- | ---------------------------- |
| `CephCluster`     | 完全な Ceph クラスターの宣言を示す |
| `CephBlockPool`   | Ceph の RBD ブロックストレージプールを管理 |
| `CephFilesystem`  | Ceph ファイルシステムを管理         |
| `CephObjectStore` | オブジェクトストレージバケットサービスを管理 |

Operator モードにより、Rook は Ceph クラスターのデプロイ、アップグレード、障害復旧、拡張・縮小などのライフサイクル管理を実現し、伝統的な Ceph のインストールプロセスの複雑さを大幅に低下させます。

### 3. Kubernetes での Ceph 使用

Kubernetes は本質的に持続可能なストレージを提供していません。もし Pod がバインディングされた PVC（PersistentVolumeClaim）が信頼性のあるバックエンドを持っていない場合、高可用性、ノード間の自動復元などのストレージ能力を実現することはできません。Ceph、特に Rook 経由で統合された Ceph は、この空きを補うのに最適です。

* 可靠なデータの持続ストレージ；
* 弾性拡張能力；
* 高可用性ブロックデバイスと共有ファイルシステムをサポート；
* Kubernetes はネイティブに CSI プラグインと StorageClass 動的提供をサポート。

Rook-Ceph は真のクラウドナティブストレージソリューションを構築することができる。

## 二、学習の流れ

Ceph と Rook-Ceph には非常に複雑な内容が含まれており、初心者にとっては初期段階における最大の困難は資料が不足しているのではなく、資料が多く、体系的かつ段階的なものではないということです。効率を高め、無駄な失敗を避けるために、学習の流れを 3 つの段階に分けて、実践を通じて関連するツールに関する理解を築くことをお勧めします。

### 1. 階段一：概念の構築

#### 推奨リソース

- 公式ドキュメント：https://rook.github.io/docs/rook/latest-release/Getting-Started/intro/
- 中文紹介：B 站で「Ceph 入門シリーズ」を検索
- ChatGPT などの用語検索

#### キー目標：Ceph と Rook-Ceph の設計動機と関係を理解し、核心コンポーネントの役割を整理すること

| 理解すべき問題                                               | 推奨質問の形式例                                            | なぜ重要なのか                                                   |
| ------------------------------------------------------------ | ----------------------------------------------------------- | ------------------------------------------------------------ |
| Ceph はどのような問題を解決するために生まれたのですか？      | Ceph と従来の集中型ストレージシステムの根本的な違いを簡潔に説明してください。 | Ceph が分散 + 容錯 + 非中央集権的なコア思想を明確に理解するため。       |
| Ceph と Rook-Ceph はどのような関係ですか？                   | Kubernetes で Rook-Ceph を使用すると Ceph を使っていることになりますか？Rook は何をしていますか？ | Rook が Ceph の運用ロジックをカプセル化しているという概念を理解し、両者を混同しないようにするため。 |
| Ceph の核心コンポーネントは何か？それぞれの責任は何ですか？ | MON、OSD、MGR、MDS の役割と相互作用を説明してください。     | 後のすべてのコマンド操作と障害診断の入口を明確にするため。           |
| RBD、オブジェクトストレージ、ファイルシステムとは何ですか？Kubernetes ではどれを使用していますか？ | Kubernetes で PVC を使用する際、Ceph のブロックストレージなのか、それ以外の形式なのか？ | Ceph がブロックストレージなのか、クラウドディスクなど他の概念を含むのかを明確にするため。 |
| なぜ Kubernetes で Ceph をデプロイするには Rook を使用する必要がありますか？ | Rook 以外で Ceph を直接デプロイすることは可能ですか？その違いは何ですか？ | Kubernetes と伝統的アーキテクチャの違い、特に宣言的リソースという思想を理解するため。 |

### 2. 階段二：環境の習熟

#### 基本目標

- K8s で toolbox にアクセスし、基本的な診断と状態コマンドを実行する方法を学ぶ；
- `ceph status`、`osd tree` などのコマンドの意味を読み取り理解する；
- `kubectl` を使って Rook のリソースオブジェクトを管理する基本を学ぶ。

#### キー目標：Rook-Ceph デプロイ後のクラスターに存在するリソースを理解し、toolbox と K8s オブジェクトの関係を把握し、基礎的なクエリを独立して行うことができるようになること。

| 理解すべき問題                                               | 推奨質問の形式例                                             | なぜ重要なのか                                                   |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| toolbox に入る方法は？それはどこに接続しているのですか？      | rook-ceph-tools という Pod はどのようにして Ceph クラスターに接続しているのですか？Ceph も一緒に実行しているのですか？ | toolbox が Ceph 本体ではなく、リモートクライアントであることを誤解しないようにするため。 |
| `ceph status` で出力される HEALTH_WARN とはどういうことですか？どのように追跡しますか？ | `ceph health detail` で mon quorum lost が表示された場合、どういう状況ですか？ | 各診断出力には問題の手がかりが含まれており、逐次的に特定する必要があるため。 |
| Ceph はどのようにしてディスクをストレージリソースに変換しますか？OSD とハードディスクの関係は？ | OSD は物理ディスクとどのように対応していますか？複数の OSD はディスクを共有できますか？ | 後の `ceph osd down` やディスク障害の操作論を学ぶため。             |
| Ceph の Pool とは何ですか？なぜ各 PVC が Pool に対応するのですか？ | なぜ複数の Pool を必要とするのですか？Pool の複製数と性能・容量の関係は？ | Pool はリソースの区画単位であり、これを理解しないとパフォーマンスや災害対策の調整ができないため。 |
| Kubernetes の StorageClass と Ceph の BlockPool はどのようにバインディングされますか？ | PVC から Ceph RBD へのリソースの階層的なマッピングは？RBD は誰が作成していますか？ | K8s → Rook → Ceph の制御ルートを整理し、データストレージの位置と負荷の所属を分析するため。 |

### 3. 階段三：実践練習

#### 基本目標

- Ceph クラスターの日常的なメンテナンスの基本操作を習得する；
- 新しいストレージプールから PVC をバインドし、アプリケーションを実行するプロセスを完了する；
- 多くの一般的な障害（少なくとも原因の特定）を独立してトラブルシューティングできる。

#### キー目標：Pool、RBD、PVC を作成・操作し、一般的なエラーを処理し、Rook のアップグレードと Ceph 操作チェーンを習得すること。

| 理解すべき問題                                  | 推奨質問方式                                                 | なぜ重要                                          |
| ----------------------------------------------- | ------------------------------------------------------------ | --------------------------------------------------- |
| ある RBD が正しく作成され、PVC にバインドされているかをどう判断しますか？ | PVC から対応する Ceph RBD 名前を逆引きする方法は？          | ストレージが正しく設定されているか確認し、特にマウント失敗時のトラブルシューティングに役立つ。 |
| Pool の複製数の設定は性能と耐障害性にどのような影響を与えますか？ | 三複製のプールでは必ず三倍のスペースが消費されますか？もし二台のマシンしか使えない場合はどうなりますか？ | Pool パラメーターが性能と容量に与える影響を理解することは、最適化の核心スキルです。 |
| スナップショットを作成した後にどう復元しますか？元データに影響はありますか？ | Ceph RBD スナップショットの rollback は元データを上書きしますか？復元操作のデモは？ | スナップショットは実験やテスト時の重要なツールであり、誤って削除した際の対応に使われます。 |
| なぜ rook-ceph-osd-xxx pod がダウンしていますか？どう分析しますか？ | OSD pod が起動失敗した場合、ログや ceph コマンドを使って原因を分析する方法は？ | このような問題は頻繁に発生するため、ログ診断とハードウェアマッピングのロジックをマスターする必要があります。 |
| Rook のアップグレード中に観察すべき重要な指標は何か？ | v1.14 から v1.15 へのアップグレード時、どの pod を先に更新するべきで、どのリソースは変更不可ですか？ | 無中断アップグレードを行い、ストレージデータを失わない方法を学ぶため。 |

> **テクニック**
>
> - 実際に作成→マウント→書き込み→削除の完全なフローを実施する；
> - 試行錯誤を恐れず、特にテスト環境で意図的に OSD down/MON 故障などを作り出す；
> - 大規模モデルにエラーメッセージや CRD フィールドの用途を説明してもらう。

## 三、よく使うコマンド

### 1. 基本情報の確認と健康チェック

| 操作                 | コマンド                       | 用途説明                                        |
| -------------------- | -------------------------- | ----------------------------------------------- |
| 全体の健康状態を確認     | `ceph -s` または `ceph status` | クラスターが `HEALTH_OK` 状態であることを確認し、警告内容があれば分析する |
| クラスターのストレージ使用状況を確認 | `ceph df`                  | どの pool が最も多くのスペースを占有しているかを判断する |
| 全コンポーネントのバージョンを確認     | `ceph versions`            | アップグレード後のバージョンが統一されているかを確認する |
| クラスターのホストノードトポロジーを確認 | `ceph osd tree`            | OSD の分布を判断し、障害ノードの特定に特に重要 |
| MON の情報を確認        | `ceph mon dump`            | quorum 数と障害復旧に必要な情報を確認する |
| クラスターのアラームの詳細を確認     | `ceph health detail`       | 各アラームの具体的な情報を取得し、コンポーネントの位置を特定する |

### 2. OSD 操作

| 操作                  | コマンド                               | 用途説明                    |
| --------------------- | ---------------------------------- | --------------------------- |
| 全 OSD の一覧を確認     | `ceph osd ls`                      | OSD の番号を確認する             |
| OSD の状態を確認         | `ceph osd stat`                    | 全 OSD が up/in しているかを確認する |
| 特定の OSD の詳細状態を確認 | `ceph osd dump`                    | OSD が in/out している状況を特定するためによく使用される |
| 指定の OSD をオフラインにする | `ceph osd out <id>`                | ディスクを計画的にオフラインにしたり、ノードメンテナンス時に使用する |
| 指定の OSD をオンラインに戻す | `ceph osd in <id>`                 | ディスクを再利用するか、誤操作で復元する |
| 特定の OSD をダウン状態にマーク | `ceph osd down <id>`               | 故障復旧のテスト操作に使用される |
| OSD の再バランスをトリガする | `ceph osd reweight-by-utilization` | データ分布が不均等な場合に使用される |

### 3. Pool 管理

| 操作           | コマンド                                                         | 用途説明                       |
| -------------- | ------------------------------------------------------------ | ------------------------------ |
| 既存の pool を確認 | `ceph osd pool ls`                                           | 現在のストレージ構成を迅速に把握する |
| pool の詳細を確認 | `ceph osd pool get <pool> all`                               | レプリカ数、符号方式などのパラメータを確認する |
| pool を作成      | `ceph osd pool create mypool 128 128`                        | 実験環境で異なるサイズの pool を試す |
| pool を削除      | `ceph osd pool delete mypool mypool --yes-i-really-really-mean-it` | 小心に使用し、実験環境専用に限定する |
| レプリカ数を 3 に設定 | `ceph osd pool set mypool size 3`                            | データの冗長性を保証するが、スペースの消費が増加する |

### 4. RBD 操作練習

| 操作          | コマンド                                         | 用途説明                            |
| ------------- | -------------------------------------------- | ----------------------------------- |
| RBD イメージを作成 | `rbd create myrbd --size 1024 --pool mypool` | MB 単位で、PVC にバインドする前にイメージを作成する |
| イメージを確認      | `rbd ls -p mypool`                           | 成功的に作成されたかを確認する         |
| イメージの情報を取得 | `rbd info mypool/myrbd`                      | イメージのサイズや使用状況を確認する     |
| イメージを削除      | `rbd rm mypool/myrbd`                        | 実験用イメージを削除し、スペースを解放する |
| スナップショットを作成 | `rbd snap create mypool/myrbd@snap1`         | スナップショットと復元機能のテストに使用される |
| スナップショットをロールバック | `rbd snap rollback mypool/myrbd@snap1`       | 誤って削除したデータの復元をシミュレーションする |

### 5. ファイルシステム操作（MDS をデプロイした後にのみ利用可能）

| 操作             | コマンド                                       | 用途説明                        |
| ---------------- | ------------------------------------------ | ------------------------------- |
| ファイルシステムを作成 | `ceph fs new myfs myfs_metadata myfs_data` | NFS のような共有マウントをサポート |
| 全ファイルシステムを確認 | `ceph fs ls`                               | ファイルシステムが有効かどうかを確認する |
| ファイルシステムの状態を確認 | `ceph fs status`                           | アクティブな MDS ノードとクライアント接続数を確認する |

## 四、練習シナリオ

### 1. シナリオ一：大規模モデル訓練サービス用に独立したデータボリュームを作成

実験室で PyTorch 基盤の大規模モデル訓練サービスをデプロイしており、各ユーザーが独自のデータストレージボリュームを訓練コンテナにマウントしたいと考えています。あなたは管理者として、以下の手順を実行する必要があります。

1. モデル訓練データ専用のブロックストレージプール `ml-training-pool` を作成；
2. このプールを Kubernetes の StorageClass にバインドし、ユーザーが PVC で利用できるようにする；
3. PVC を作成し、それが成功して Ceph クラスター内で対応する RBD イメージを生成されていることを確認する；
4. toolbox を使用して、このブロックデバイスのステータスや容量などの詳細情報を確認し、利用可能性を確認する。

### 2. シナリオ二：ノードディスク障害をシミュレーションし、Ceph データ再バランスプロセスを観察

Ceph の生産環境での耐障害能力をシミュレーションするため、OSD ノードの異常オフラインをシミュレーションし、Ceph の自己修復メカニズムが効果的に機能するかを観察する必要があります。

1. 現存のクラスターから 1 つの OSD を選び、それを `out` にマークし、ディスクがオフラインになることをシミュレーションします；
2. Ceph がデータの移動、再バランス、健康状態の変化をトリガーするかを観察します；
3. OSD tree とクラスターの状態変化を確認し、レプリカの再構築と容量の再分布プロセスを記録します；
4. 故障を修復した後、OSD を `in` にマークし、システムの回復プロセスを観察します。

### 3. シナリオ三：スナップショットとロールバックを使って訓練データの保護と復元を行う

大規模モデルの訓練前に、ユーザーの訓練データボリュームに対して復元可能なスナップショットを提供し、誤って削除するのを防ぐ必要があります。シミュレーションのシナリオは以下の通りです。

1. 既存のブロックストレージボリューム（PVC に該当）にスナップショットを作成し、`@pretrain` と名付けます；
2. ユーザーが重要な訓練データを誤って削除したり、途中で異常なデータを書き込んだりしたと仮定します；
3. Ceph のスナップショットロールバック機能を使って、この RBD ボリュームを訓練前のスナップショット状態に復元します；
4. ロールバック後のデータの一貫性を確認し、スナップショットがシステムのパフォーマンスと容量に与える影響を理解します。

### 4. シナリオ四：共有ボリュームをデプロイし、分散訓練ログの収集をサポートする

実験室は分散訓練の実験を計画しており、複数の Pod インスタンスが同じディレクトリに訓練ログを書き込む必要があります。あなたは以下の手順を実行する必要があります。

1. Ceph ファイルシステム（CephFS）を作成し、MDS サービスを通じて POSIX インターフェースを提供します；
2. 複数の Pod が同時にマウントできる ReadWriteMany をサポートする StorageClass を構成します；
3. PVC を作成し、複数の Pod にマウントして、ログの並行書き込みシナリオをシミュレーションします；
4. 書き込まれたデータが一貫しているか、書き込み衝突や権限異常があるかを検証します。

### 5. シナリオ五：ストレージプールの容量が枯渇する可能性への対応策をシミュレーションする

訓練タスクが密集して提出されるピーク時、ある Ceph ブロックストレージプールの残容量が枯渇する可能性があることに気付きます。あなたは以下の手順を実行する必要があります。

1. toolbox を使って各 Pool の使用率とレプリカ構成を確認します；
2. 現在の Pool に空き状態で未バインドされている RBD イメージがあるかを分析し、リサイクルを検討します；
3. 実際には容量が不足している場合、いくつかの Pool のレプリカ数を 3 から 2 に減少させます（これはテストシナリオに限ります）；
4. エクスパンションの可能性を評価し、新しいノードや OSD を追加し、システムが自動的に再バランスするかを観察します。

### 6. シナリオ六：使用されていないイメージと Pool をクリーンアップし、ストレージスペースを解放する

クラスター内に複数の使用されていない PVC およびそれらに該当する RBD イメージが存在していることに気づきます。ユーザーが手動でクリーンアップしていないため、あなたは以下の手順を実行する必要があります。

1. これらの PVC が所属する Pod がすでに削除されているかを確認します；
2. これらの PVC にバインドされた RBD イメージを見つけ、再度マウントされていないことを確認します；
3. toolbox を使ってこれらのイメージを削除し、使用されていない BlockPool をクリーンアップします（依存がない場合）；
4. クラスターの総容量変化を再度確認し、スペースの回収が成功したことを確認します。