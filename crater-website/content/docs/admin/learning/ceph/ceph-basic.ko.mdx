---
title: "Rook-Ceph 연습 가이드"
description: "Rook-Ceph 초보자용 가이드입니다!"
---

> 이 가이드는 Ceph와 분산 스토리지 경험 전혀 없는 분들을 대상으로 하며, Rook-Ceph를 빠르게 이해하고 실제로 사용하는 방법을 안내합니다.

## 1. 전제 배경

Rook-Ceph를 실습하기 전에, **Ceph**와 **Rook-Ceph**라는 두 가지 핵심 개념을 근본적으로 이해하는 것이 중요합니다. 이들은 분산 스토리지 시스템의 핵심 역량과 Kubernetes 상의 자동화 운영 솔루션을 각각 나타냅니다.

### 1. Ceph

**Ceph는 오픈소스 분산 스토리지 시스템**으로, Sage Weil이 시작했으며, 대규모 스토리지 환경에서 데이터 일관성, 가용성 및 확장성을 해결하기 위해 설계되었습니다. 전통적인 집중형 스토리지 솔루션과 달리 Ceph는 단일 컨트롤러에 의존하지 않고, 대등한 노드 간 협업을 기반으로 합니다. Ceph의 핵심 설계 목표는 다음과 같습니다:

* **고확장성**: 수 TB에서 수 PB까지의 저장 용량 증가를 지원합니다.
* **고가용성 및 내결함성**: 복제본 또는 오류 교정 코드 메커니즘을 통해 노드 다운타임 시에도 데이터가 사용 가능하도록 보장합니다.
* **통합 스토리지 모델**: 블록 장치(Block), 오브젝트 스토리지(Object), 파일 시스템(File)의 접근 방식을 모두 지원합니다.

Ceph 클러스터는 주로 다음 핵심 구성 요소로 구성됩니다:

| 구성 요소 | 기능 설명 |
| --- | --- |
| MON(Monitor) | 클러스터 상태, 건강 점검, 주 장치 선출 등 메타데이터 서비스를 제공합니다. |
| OSD(Object Storage Daemon) | 데이터의 실제 읽기/쓰기, 복제, 복구 등 핵심 기능을 담당합니다. |
| MGR(Manager) | 모니터링, 통계 및 플러그인 확장 기능을 제공합니다. |
| MDS(Metadata Server, 선택 사항) | 파일 시스템 지원 시 디렉터리 트리 메타데이터를 관리합니다. |

일반적으로 Ceph 클러스터는 3개 이상의 MON이 필요하며, 여러 OSD가 각 노드의 물리 디스크에 마운트되어 데이터 저장 능력을 공유합니다.

### 2. Rook-Ceph

**Rook은 Kubernetes 기반의 스토리지 오케스트레이터(Operator)**이며, **Pod처럼 스토리지 시스템을 관리할 수 있도록 설계되었습니다**. Rook-Ceph는 이 중 가장 성숙하고 널리 사용되는 백엔드 중 하나이며, Ceph의 Kubernetes 상의 배포 및 관리 과정을 간소화하는 데 사용됩니다.

Rook-Ceph는 Ceph의 배포 및 유지 관리를 Kubernetes의 사용자 정의 리소스(Custom Resources)로 추상화합니다. 이는 다음과 같습니다:

| 사용자 정의 리소스 | 설명 |
| --- | --- |
| `CephCluster` | 완전한 Ceph 클러스터 선언을 나타냅니다. |
| `CephBlockPool` | Ceph의 RBD 블록 스토리지 풀을 관리합니다. |
| `CephFilesystem` | Ceph 파일 시스템을 관리합니다. |
| `CephObjectStore` | 오브젝트 스토리지 버킷 서비스를 관리합니다. |

Operator 모델을 통해 Rook은 Ceph 클러스터의 배포, 업그레이드, 장애 복구, 확장 및 축소 등 생명주기 관리를 실현하며, 전통적인 Ceph 설치 과정의 복잡성을 크게 줄입니다.

### 3. Kubernetes에서 Ceph 사용

Kubernetes는 본래 의미상의 지속 가능한 저장을 제공하지 않습니다. 만약 Pod이 PVC(PersistentVolumeClaim)에 바인딩된 경우, 신뢰할 수 있는 백엔드가 없으면 고가용성, 크로스 노드, 자동 복구 기능을 갖춘 저장 기능을 달성할 수 없습니다. Ceph, 특히 Rook과 통합된 Ceph는 이 부족한 부분을 보완합니다.

* 신뢰성 있는 데이터 지속 저장;
* 탄력적 확장;
* 고가용성 블록 장치와 공유 파일 시스템 지원;
* Kubernetes에서 CSI 플러그인과 StorageClass 동적 제공을 지원합니다.

Rook-Ceph는 진정한 클라우드 네이티브 스토리지 솔루션을 구축할 수 있습니다.

## 2. 학습 경로

Ceph와 Rook-Ceph는 내용이 복잡하며, 초보자에게서 가장 큰 어려움은 자료가 부족하지 않지만, 체계성과 단계성이 부족하다는 점입니다. 효율을 높이고 비효율적인 실수를 피하기 위해, 학습 경로를 세 단계로 나누고, 실무에서 관련 도구에 대한 인식을 구축하는 것이 좋습니다.

### 1. 단계 1: 개념 확립

#### 추천 자료

- 공식 문서: https://rook.github.io/docs/rook/latest-release/Getting-Started/intro/
- 중국어 인트로: Bilibili에서 Ceph 입문 시리즈 검색
- ChatGPT 등으로 용어 확인

#### 핵심 목표: Ceph와 Rook-Ceph의 설계 동기와 관계를 이해하고, 핵심 구성 요소의 역할을 분명히 하기

| 이해해야 할 문제 | 추천 질문 형식 | 왜 중요한가 |
| --- | --- | --- |
| Ceph는 어떤 문제를 해결하기 위해 탄생했나요? | Ceph와 전통적인 집중형 스토리지 시스템의 근본적인 차이를 간략히 설명하십시오. | Ceph의 분산 + 내결함성 + 분산화라는 핵심 아이디어를 명확히 하기 위해. |
| Ceph와 Rook-Ceph는 어떤 관계인가요? | K8s에서 Rook-Ceph를 사용하면 Ceph를 사용하는 것이며, Rook은 어떤 역할을 하나요? | Rook이 Ceph의 운영 로직을 포장한다는 개념을 이해하고, 둘을 혼동하지 않도록 하기 위해. |
| Ceph의 핵심 구성 요소는 무엇이며, 각각 무엇을 담당하나요? | MON, OSD, MGR, MDS의 역할과 상호작용을 설명하십시오. | 이후 모든 명령어 조작 및 장애 해결의 입구를 명확히 하기 위해. |
| RBD, 오브젝트 스토리지, 파일 시스템이 무엇이며, Kubernetes에서 사용하는 것은 무엇인가요? | Kubernetes에서 PVC를 사용할 때는 Ceph의 블록 스토리지가 아닌 다른 형태를 사용하나요? | Ceph가 블록 스토리지인지, 클라우드 디스크 등 다른 개념을 포함하는지 명확히 하기 위해. |
| Kubernetes에서 Ceph를 배포할 때 왜 Rook을 사용하나요? | Rook 없이도 직접 Ceph를 배포할 수 있나요? 차이점은 무엇인가요? | Kubernetes와 전통 아키텍처의 차이, 특히 선언형 리소스 아이디어를 이해하기 위해. |

### 2. 단계 2: 환경 익히기

#### 기본 목표

- K8s에서 toolbox에 들어가기, 기본 진단 및 상태 명령 실행 방법을 배우기;
- `ceph status`, `osd tree` 등 명령어의 의미를 읽고 이해할 수 있도록;
- 기본적으로 `kubectl`을 사용하여 Rook 리소스 객체를 관리할 수 있도록.

#### 핵심 목표: Rook-Ceph 배포 후 클러스터 내의 리소스를 이해하고, toolbox와 K8s 객체 간의 연결 관계를 파악하며, 기본적인 쿼리 작업을 독립적으로 수행할 수 있도록.

| 이해해야 할 문제 | 추천 질문 형식 | 왜 중요한가 |
| --- | --- | --- |
| 어떻게 toolbox에 들어가고, 이는 실제로 어디에 연결되어 있나요? | `rook-ceph-tools`라는 Pod은 Ceph 클러스터에 어떻게 연결되어 있나요? Ceph도 실행되고 있나요? | toolbox가 Ceph 자체가 아니라 원격 클라이언트라는 오해를 피하기 위해. |
| `ceph status`에서 나온 `HEALTH_WARN`은 무엇을 의미하며, 어떻게 추적해야 하나요? | `ceph health detail`에서 `mon quorum lost`는 어떤 상황인가요? | 각 진단 출력에는 문제의 단서가 포함되어 있으며, 이를 단계별로 추적해야 합니다. |
| Ceph는 어떻게 디스크를 스토리지 자원으로 만드나요? OSD와 디스크는 어떤 관계인가요? | OSD는 물리 디스크와 어떻게 대응되나요? 여러 OSD가 동일한 디스크를 공유할 수 있나요? | 이후 `ceph osd down` 또는 디스크 고장 시의 작업 논리를 배우기 위해. |
| Ceph의 Pool은 무엇이며, 각 PVC는 왜 Pool에 해당하나요? | 왜 여러 개의 Pool이 필요한가요? Pool의 복제 수와 성능, 공간 사이의 관계는 무엇인가요? | Pool은 분할 자원 단위이며, 이를 모르면 성능 최적화 및 재해 대응 전략을 설정할 수 없습니다. |
| Kubernetes의 StorageClass와 Ceph의 BlockPool은 어떻게 연결되나요? | PVC에서 Ceph RBD로의 자원 매핑은 어떻게 이루어지나요? RBD는 누가 생성하나요? | K8s → Rook → Ceph의 제어 체인을 이해하고, 데이터 저장 위치와 부하 속성을 분석하기 위해. |

### 3. 단계 3: 직접 실습

#### 기본 목표

- Ceph 클러스터 일상적인 유지 관리 기초 작업을 익히기;
- 저장 풀 생성 후 PVC에 바인딩하여 애플리케이션을 실행하는 흐름을 완료할 수 있도록;
- 대부분의 일반적인 오류를 독립적으로 진단하고 원인을 파악할 수 있도록.

#### 핵심 목표: Pool, RBD, PVC를 생성 및 조작하고, 일반적인 오류를 처리하며, Rook 업그레이드 및 Ceph 작업 체인을 이해할 수 있도록.

| 이해해야 할 문제 | 추천 질문 형식 | 왜 중요한가 |
| --- | --- | --- |
| 특정 RBD가 올바르게 생성되었고, 특정 PVC에 바인딩되었는지 어떻게 판단하나요? | PVC로부터 해당하는 Ceph RBD 이름을 역추적하는 방법은 무엇인가요? | 저장이 올바르게 구성되었는지 확인하는 방법, 특히 마운트 실패 시의 진단을 배우기 위해. |
| Pool의 복제 수 설정이 성능 및 내결함성에 어떤 영향을 주나요? | 3 복제 풀에서는 반드시 3배의 공간이 소비되는가요? 만약 두 대의 머신만 사용한다면 어떻게 되나요? | Pool 매개변수가 성능과 용량에 미치는 영향은 최적화의 핵심 기술입니다. |
| 스냅샷을 생성한 후 어떻게 복구하고, 이는 기존 데이터에 영향을 주나요? | Ceph RBD 스냅샷 rollback은 기존 데이터를 덮어쓰나요? 복구 작업을 어떻게 시연하나요? | 스냅샷은 실험/테스트 시 중요한 도구이며, 실수로 인한 데이터 삭제를 방지하는 데 사용됩니다. |
| 왜 `rook-ceph-osd-xxx` pod가 죽었나요? 어떻게 분석하나요? | OSD pod가 시작 실패 시, 로그나 ceph 명령어로 원인을 분석하는 방법은 무엇인가요? | 이러한 문제는 자주 발생하므로, 로그 진단과 하드웨어 매핑 논리를 알아야 합니다. |
| Rook 업그레이드 과정에서 어떤 핵심 지표를 관찰해야 하나요? | v1.14에서 v1.15로 업그레이드 시, 어떤 pod가 먼저 업데이트되어야 하고, 어떤 자원은 변경할 수 없는가요? | 무중단 업그레이드를 학습하고, 저장 데이터 손실을 방지해야 합니다. |

> **팁**
>
> - 실제 생성 → 마운트 → 쓰기 → 삭제의 완전한 흐름을 수행하십시오;
> - 실수를 두려워하지 말고, 특히 테스트 환경에서 의도적으로 OSD down/MON 장애 등을 유도하십시오;
> - 오류 메시지와 CRD 필드 용도에 대한 대규모 모델의 설명을 자주 요청하십시오.

## 3. 자주 사용하는 명령어

### 1. 기본 정보 확인 및 건강 상태 점검

| 작업 | 명령 | 용도 설명 |
| --- | --- | --- |
| 전체 건강 상태 확인 | `ceph -s` 또는 `ceph status` | 클러스터가 `HEALTH_OK` 상태인지 확인하고, 아니라면 경고 내용을 분석하십시오. |
| 클러스터 공간 사용량 확인 | `ceph df` | 어떤 pool이 가장 많은 공간을 사용하고 있는지 확인하십시오. |
| 모든 구성 요소 버전 확인 | `ceph versions` | 업그레이드 후 버전이 통일되었는지 확인하십시오. |
| 클러스터 호스트 노드 토폴로지 확인 | `ceph osd tree` | OSD 분포를 확인하고, 장애 노드를 식별하는 데 특히 중요합니다. |
| MON 정보 확인 | `ceph mon dump` | quorum 수와 장애 복구 요구 사항을 확인하십시오. |
| 클러스터 경고 세부 정보 확인 | `ceph health detail` | 각 경고의 구체적인 정보와 구성 요소 위치를 확인하십시오. |

### 2. OSD 작업

| 작업 | 명령 | 용도 설명 |
| --- | --- | --- |
| 모든 OSD 목록 확인 | `ceph osd ls` | OSD ID를 확인하십시오. |
| OSD 상태 확인 | `ceph osd stat` | 모든 OSD가 up/in 상태인지 확인하십시오. |
| 특정 OSD의 상세 상태 확인 | `ceph osd dump` | OSD in/out 상태를 파악하는 데 자주 사용됩니다. |
| 특정 OSD를 하선 처리 | `ceph osd out <id>` | 디스크/유지 보수 노드를 계획적으로 하선할 때 사용됩니다. |
| 특정 OSD를 다시 올라오게 하기 | `ceph osd in <id>` | 디스크 사용 또는 오류 복구를 위해 사용됩니다. |
| 특정 OSD를 수동으로 장애 상태로 표시 | `ceph osd down <id>` | 장애 복구 시나리오의 테스트 작업에 사용됩니다. |
| OSD 재균형 트리거 | `ceph osd reweight-by-utilization` | 데이터 분포가 불균형할 때 사용됩니다. |

### 3. Pool 관리

| 작업 | 명령 | 용도 설명 |
| --- | --- | --- |
| 기존 Pool 확인 | `ceph osd pool ls` | 현재의 저장 구조를 빠르게 파악하십시오. |
| Pool 세부 정보 확인 | `ceph osd pool get <pool> all` | 복제 수, 인코딩 방식 등 매개변수를 확인하십시오. |
| Pool 생성 | `ceph osd pool create mypool 128 128` | 실험 환경에서 다양한 크기의 Pool을 시도할 수 있습니다. |
| Pool 삭제 | `ceph osd pool delete mypool mypool --yes-i-really-really-mean-it` | 주의 깊게 사용하십시오. 실험 환경에서만 사용하십시오. |
| 복제 수를 3으로 설정 | `ceph osd pool set mypool size 3` | 데이터의 중복도를 보장하지만, 공간 사용량이 증가합니다. |

### 4. RBD 작업 연습

| 작업 | 명령 | 용도 설명 |
| --- | --- | --- |
| RBD 이미지 생성 | `rbd create myrbd --size 1024 --pool mypool` | PVC에 바인딩하기 전에 이미지를 생성해야 합니다. |
| 이미지 확인 | `rbd ls -p mypool` | 생성 여부를 확인하십시오. |
| 이미지 정보 확인 | `rbd info mypool/myrbd` | 이미지의 크기와 사용 상황을 확인하십시오. |
| 이미지 삭제 | `rbd rm mypool/myrbd` | 테스트용 이미지를 삭제하고 공간을 해제하십시오. |
| 스냅샷 생성 | `rbd snap create mypool/myrbd@snap1` | 스냅샷과 복구 기능 테스트에 사용됩니다. |
| 스냅샷 롤백 | `rbd snap rollback mypool/myrbd@snap1` | 실수로 인한 데이터 복구를 시뮬레이션합니다. |

### 5. 파일 시스템 작업 (MDS가 배포된 경우에만 가능)

| 작업 | 명령 | 용도 설명 |
| --- | --- | --- |
| 파일 시스템 생성 | `ceph fs new myfs myfs_metadata myfs_data` | NFS와 유사한 공유 마운트를 지원합니다. |
| 모든 파일 시스템 확인 | `ceph fs ls` | 파일 시스템이 정상적으로 작동하는지 확인하십시오. |
| 파일 시스템 상태 확인 | `ceph fs status` | 활성 MDS 노드와 클라이언트 연결 수를 확인하십시오. |

## 4. 연습 시나리오

### 1. 시나리오 1: 대규모 모델 훈련 서비스를 위한 독립 데이터 볼륨 생성

실험실에서 PyTorch 기반의 대규모 모델 훈련 서비스를 배포했으며, 각 사용자가 독립적인 데이터 저장 볼륨을 훈련 컨테이너에 마운트하려 합니다. 당신은 관리자로서 다음을 수행해야 합니다:

1. `ml-training-pool`이라는 이름의 블록 스토리지 풀을 생성하여 모델 훈련 데이터에 전용으로 사용합니다;
2. 이 풀을 Kubernetes의 StorageClass에 바인딩하여 사용자가 PVC에서 사용할 수 있도록 합니다;
3. PVC를 생성하고, 이가 성공적으로 바인딩되어 Ceph 클러스터 내에서 대응하는 RBD 이미지가 생성되었는지 확인합니다;
4. toolbox를 사용하여 이 블록 장치의 상태, 용량 등의 세부 정보를 확인하고, 가용성을 확인합니다.

### 2. 시나리오 2: 노드 디스크 장애 시뮬레이션 및 Ceph 데이터 재균형 과정

Ceph의 생산 환경에서의 내결함성 능력을 연습하기 위해, 하나의 OSD 노드의 비정상 하선을 시뮬레이션하고 Ceph의 자동 복구 메커니즘이 작동하는지 관찰해야 합니다.

1. 기존 클러스터에서 하나의 OSD를 선택하고, 이를 `out` 상태로 표시하여 디스크 오프라인을 시뮬레이션합니다;
2. Ceph가 데이터 이동, 재균형 및 건강 상태 변화를 트리거하는지 관찰합니다;
3. OSD tree와 클러스터 상태 변화를 확인하고, 복제본 재구성 및 용량 재분배 과정을 기록합니다;
4. 장애가 복구된 후, 이 OSD를 `in` 상태로 표시하고 시스템 복구 과정을 관찰합니다.

### 3. 시나리오 3: 스냅샷 및 롤백을 활용한 훈련 데이터 보호 및 복구

대규모 모델 훈련 전에 사용자의 훈련 데이터 볼륨에 복구 가능한 스냅샷을 제공하여 실수로 인한 데이터 삭제를 방지하려 합니다. 시뮬레이션 시나리오는 다음과 같습니다:

1. 기존 블록 스토리지 볼륨(대응 PVC)에 `@pretrain`이라는 이름의 스냅샷을 생성합니다;
2. 사용자가 중요한 훈련 데이터를 실수로 삭제하거나, 중간에 이상한 데이터를 입력했을 경우를 가정합니다;
3. Ceph의 스냅샷 롤백 기능을 사용하여 RBD 볼륨을 훈련 전의 스냅샷 상태로 복구합니다;
4. 롤백 후 데이터 일관성을 검증하고, 스냅샷이 시스템 성능과 용량에 미치는 영향을 이해합니다.

### 4. 시나리오 4: 분산 훈련 로그 수집을 위한 공유 볼륨 배포

실험실에서 분산 훈련 실험을 계획하고 있으며, 여러 Pod 인스턴스가 동일한 디렉터리에 훈련 로그를 쓰기를 수행해야 합니다. 당신은 다음을 수행해야 합니다:

1. Ceph 파일 시스템(CephFS)을 생성하고, MDS 서비스를 통해 POSIX 인터페이스를 제공합니다;
2. 여러 Pod가 동시에 마운트할 수 있는 ReadWriteMany를 지원하는 StorageClass를 구성합니다;
3. PVC를 생성하고, 여러 Pod에 마운트하여 로그 동시 쓰기 시나리오를 시뮬레이션합니다;
4. 쓰인 데이터의 일관성을 검증하고, 쓰기 충돌 또는 권한 문제가 있는지 확인합니다.

### 5. 시나리오 5: 저장 풀 용량 고갈 대응 전략 시뮬레이션

훈련 작업이 집중적으로 제출되는 고강도 시기, 특정 Ceph 블록 스토리지 풀의 남은 용량이 부족해질 것으로 예상됩니다. 당신은 다음과 같이 대응 전략을 수행해야 합니다:

1. toolbox를 사용하여 각 Pool의 사용률과 복제 설정을 확인합니다;
2. 현재 Pool 내에서 사용되지 않고, 바인딩되지 않은 RBD 이미지가 있는지 분석하고, 정리/회수를 고려합니다;
3. 실제로 용량이 부족한 경우, 특정 Pool의 복제 수를 3에서 2로 감소시켜(테스트 환경에 한함) 대응합니다;
4. 확장 가능성 평가 후, 새로운 노드 또는 OSD를 추가하고 시스템이 자동으로 재균형되는지 관찰합니다.

### 6. 시나리오 6: 사용되지 않는 이미지 및 Pool 정리하여 저장 공간 해제

클러스터 내에 사용되지 않는 PVC 및 대응하는 RBD 이미지가 여러 개 존재하며, 사용자가 수동으로 정리하지 못했습니다. 당신은 다음과 같이 정리 작업을 수행해야 합니다:

1. 이러한 PVC가 소속된 Pod들이 이미 삭제되었는지 확인합니다;
2. 이러한 PVC가 바인딩된 RBD 이미지를 찾아서 현재 사용 중이지 않은지 확인합니다;
3. toolbox를 사용하여 이러한 이미지를 삭제하고, 더 이상 사용되지 않는 BlockPool(의존성이 없는 경우)을 정리합니다;
4. 클러스터 총 용량 변화를 다시 확인하여 공간이 성공적으로 회수되었는지 확인합니다.